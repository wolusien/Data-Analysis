---
title: 'TP5 : Classification Non Supervisée (Unsupervised Machine Learning) : Méthode
  des centres mobiles (K-MEANS CLUSTERING)'
author: "DJEBALI Wissam"
date: "3 mars 2018"
output: pdf_document
header-includes:
- \usepackage[french]{babel}
- \usepackage[utf8]{inputenc}
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(stats)
library(factoextra)
```

## Méthode des centres mobiles (K-MEANS)
<!-- http://www.sthda.com/english/articles/27-partitioning-clustering-essentials/87-k-means-clustering-essentials/ -->

**Packages R** : stats, factoextra

L'algorithme de classification par méthode des centres mobiles (KMEANS) de MacQueen, variante de l'algorithme de Forgy/Lloyd est l'une des plus connues et des plus utilisées.

**Principe de l'algorithme K-means clustering**:

On a des données d'individus qu'on souhaite classer en K groupes, tel que les individus dans un même groupe soient les plus similaires (forte similarité intra-classe), et les individus de groupes différents soient les plus dissimilaires (faible similarité inter-classe).
Chaque groupe sera représentés par son centre(centroïd) qui correspond à la moyenne des points assignés au groupe.

On veut définir les groupes tel que la variance intra-groupe (total within-cluster variation) soit minimale.

variation intra-groupe : $W(C_k)=\sum_{x_i\in C_k}(x_i-\mu_k)^2$
où $x_i$ point représentant un  individu appartenant au groupe $C_k$ et $\mu_k$ moyenne assigné au groupe $C_k$

Chaque individu $(x_i)$ est assigné à un groupe tel que la somme des variances intra-groupes(total within-cluster variation) soit minimale.

$tot.withinss=\sum^K_{k=1}W(C_k)=\sum^K_{k=1}\sum_{x_i\in C_k}(x_i-\mu_k)^2$



**K-means algorithm can be summarized as follow**:

1)Specify the number of clusters (K) to be created (by the analyst)

2)Select randomly k objects from the dataset as the initial cluster centers or means

3)Assigns each observation to their closest centroid, based on the Euclidean distance between the object and the centroid

4)For each of the k clusters update the cluster centroid by calculating the new mean values of all the data points in the cluster. The centoid of a Kth cluster is a vector of length p containing the means of all variables for the observations in the kth cluster; p is the number of variables.

5)Iteratively minimize the total within sum of square. That is, iterate steps 3 and 4 until the cluster assignments stop changing or the maximum number of iterations is reached. By default, the R software uses 10 as the default value for the maximum number of iterations.


```{r}
ir<-iris[,-5]
species = iris$Species

# Choix de K pour le clustering
fviz_nbclust(ir, kmeans, method = "wss") +
    geom_vline(xintercept = 3, linetype = 2)

# K-means avec K=3
set.seed(123)
km.res <- kmeans(ir, 3, nstart = 25)

# Print the results of kmeans
print(km.res)

# Moyennes des variables dans les 3 groupes
aggregate(ir, by=list(cluster=km.res$cluster), mean)

# Tableau des individus avec leur moyenne par variable et leur groupe
dd <- cbind(ir, cluster = km.res$cluster)
head(dd)

# Groupe de chaque observations
km.res$cluster

# Effectif des groupes
km.res$size

# Centres des groupes
km.res$centers

# Visualisation des individus en fonction de leur groupes
fviz_cluster(km.res, data = ir,
             palette = c("#2E9FDF", "#FC4E07", "#E7B800" ), 
             ellipse.type = "euclid", # Concentration ellipse
             star.plot = TRUE, # Add segments from centroids to items
             repel = TRUE, # Avoid label overplotting (slow)
             ggtheme = theme_minimal()
             )

# Etude des pétales
# Petal
kmoy3<-kmeans(ir[,c(3,4)],3,nstart=4)
kmoy3
table(kmoy3$cluster,species)
par(mfrow=c(1,2))
plot(ir[c("Petal.Length", "Petal.Width")], col=kmoy3$cluster)
points(kmoy3$centers[,c("Petal.Length", "Petal.Width")], 
       col=1:3, pch=23, cex=3)
plot(ir[c("Petal.Length", "Petal.Width")],col=iris$Species)

```

